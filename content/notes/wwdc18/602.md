---
contributors: zntfdr
---

## `ARWorldMap` persistence

After the user ends a session (say in front of a table and the user put objects on the table), the user can go back again another day in front of the same table and the app can recognize the table and put back all the objects as the user placed them as in the previous session

## Multi-User Experiences

The `ARWorldMap` are sharable and this is why we can play an ar game at the same time with multiple devices

## More robust tracking and plane detection

Both horizontal and from ARKit 1.5 vertical.

## (Real Time) Environment Texturing

![][benchImage]

Even if ARKit doesn’t know the whole scene (because the user didn't spin 360-degrees around), ARKit will use CoreML to “hallucinate” the missing parts.

## Real Time Multiple 2D Images Tracking:

Track position and orientation in each frame, pictures no need to be static

![][tableImage]

You need to import the reference images to Xcode.

## Object Tracking

Track positions of fixed objects (you can move around them but the object can’t move), you need to import a 3d model of the object into xcode, Apple gives you a (free) app to scan the object and get the 3d object

## Face Tracking

- Gaze tracking

![][eyeImage]

- Tongue tracking (as in memojii)

[tableImage]: ../../../images/notes/wwdc18/602/table.png
[benchImage]: ../../../images/notes/wwdc18/602/bench.png
[eyeImage]: ../../../images/notes/wwdc18/602/eye.png